{
  "cells": [
    {
      "cell_type": "markdown",
      "id": "9e42ed6f-0c35-4e47-9d44-8f00112efc71",
      "metadata": {
        "id": "9e42ed6f-0c35-4e47-9d44-8f00112efc71"
      },
      "source": [
        "### Taxi - v3 RL solution ###\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "d25fcafb-521d-41e0-b03d-d7b6d594f3dd",
      "metadata": {
        "tags": [],
        "id": "d25fcafb-521d-41e0-b03d-d7b6d594f3dd"
      },
      "outputs": [],
      "source": [
        "import gymnasium as gym\n",
        "\n",
        "import numpy as np\n",
        "import random\n",
        "from IPython.display import clear_output\n",
        "from time import sleep"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "dbe58e73-0c4a-45a5-9c0a-b0cc824d9824",
      "metadata": {
        "tags": [],
        "id": "dbe58e73-0c4a-45a5-9c0a-b0cc824d9824"
      },
      "outputs": [],
      "source": [
        "# Setting up an environment\n",
        "\n",
        "env = gym.make(\"Taxi-v3\", render_mode='ansi')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "8a4e859e",
      "metadata": {
        "tags": [],
        "id": "8a4e859e",
        "outputId": "65d151f2-9aec-4d5a-8df1-3b576beaf4d5"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Discrete(6) Discrete(500)\n",
            "1\n",
            "496\n"
          ]
        }
      ],
      "source": [
        "print(env.action_space,env.observation_space)\n",
        "print(env.action_space.sample())\n",
        "print(env.observation_space.sample())"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "894ca536",
      "metadata": {
        "tags": [],
        "id": "894ca536",
        "outputId": "6cc372d9-4882-4ce0-fc92-17aaebf7fc38"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "(212,\n",
              " -1,\n",
              " False,\n",
              " False,\n",
              " {'prob': 1.0, 'action_mask': array([1, 1, 1, 0, 0, 0], dtype=int8)})"
            ]
          },
          "execution_count": 4,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "env.reset()\n",
        "result = env.step(0)\n",
        "result"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "f5d831cc-989d-4ee0-8090-7a2d4ca114d5",
      "metadata": {
        "tags": [],
        "id": "f5d831cc-989d-4ee0-8090-7a2d4ca114d5",
        "outputId": "c7e5342b-d14d-40a7-e39b-72f351578bd8"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "(500, 6)\n"
          ]
        }
      ],
      "source": [
        "# Set up the Q-table\n",
        "\n",
        "q_table = np.zeros([env.observation_space.n, env.action_space.n])\n",
        "print(q_table.shape)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "2c4fb4c7-c694-45cc-9d14-d89891e976dc",
      "metadata": {
        "tags": [],
        "id": "2c4fb4c7-c694-45cc-9d14-d89891e976dc",
        "outputId": "735a067a-97f1-4cad-a7ec-e7946d19b8c9"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Episode: 100000\n",
            "Training finished.\n",
            "\n",
            "CPU times: user 33.7 s, sys: 7.48 s, total: 41.1 s\n",
            "Wall time: 35.9 s\n"
          ]
        }
      ],
      "source": [
        "%%time\n",
        "\"\"\"Training the agent\"\"\"\n",
        "\n",
        "frames = []\n",
        "\n",
        "# Hyperparameters\n",
        "alpha = 0.1\n",
        "gamma = 0.6\n",
        "epsilon = 0.1\n",
        "\n",
        "# For plotting metrics\n",
        "all_epochs = []\n",
        "all_penalties = []\n",
        "\n",
        "for i in range(1, 100001):\n",
        "    state = env.reset()[0]\n",
        "\n",
        "    epochs, penalties, reward, = 0, 0, 0\n",
        "    done = False\n",
        "\n",
        "    while not done:\n",
        "        if random.uniform(0, 1) < epsilon:\n",
        "            action = env.action_space.sample() # Explore action space\n",
        "        else:\n",
        "            action = np.argmax(q_table[state]) # Exploit learned values\n",
        "\n",
        "        next_state, reward, done, info, _ = env.step(action)\n",
        "\n",
        "        old_value = q_table[state, action]\n",
        "        next_max = np.max(q_table[next_state])\n",
        "\n",
        "        new_value = (1 - alpha) * old_value + alpha * (reward + gamma * next_max)\n",
        "        q_table[state, action] = new_value\n",
        "\n",
        "        if reward == -10:\n",
        "            penalties += 1\n",
        "\n",
        "        # Put each rendered frame into dict for animation\n",
        "        frames.append({\n",
        "            'frame': env.render(),\n",
        "            'state': state,\n",
        "            'action': action,\n",
        "            'reward': reward\n",
        "        })\n",
        "        state = next_state\n",
        "        epochs += 1\n",
        "\n",
        "\n",
        "    if i % 100 == 0:\n",
        "        clear_output(wait=True)\n",
        "        print(f\"Episode: {i}\")\n",
        "\n",
        "print(\"Training finished.\\n\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "3e3ada20-1cdf-4b46-bca5-5585ac4850c3",
      "metadata": {
        "tags": [],
        "id": "3e3ada20-1cdf-4b46-bca5-5585ac4850c3"
      },
      "outputs": [],
      "source": [
        "# # Run the frames to see how the agent did over the episodes\n",
        "\n",
        "def print_frames(frames):\n",
        "    for i, frame in enumerate(frames):\n",
        "        clear_output(wait=True)\n",
        "        print(frame['frame'])\n",
        "        print(f\"Timestep: {i + 1}\")\n",
        "        print(f\"State: {frame['state']}\")\n",
        "        print(f\"Action: {frame['action']}\")\n",
        "        print(f\"Reward: {frame['reward']}\")\n",
        "        print(f\"Episode: {frame['episode']}\")\n",
        "        sleep(.1)\n",
        "\n",
        "# print_frames(frames)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "2a1dc532-b19e-4da3-b847-a1093a568da0",
      "metadata": {
        "tags": [],
        "id": "2a1dc532-b19e-4da3-b847-a1093a568da0",
        "outputId": "a319d0d9-7073-4ab5-fb3d-707422921131"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "+---------+\n",
            "|\u001b[35m\u001b[34;1m\u001b[43mR\u001b[0m\u001b[0m\u001b[0m: | : :G|\n",
            "| : | : : |\n",
            "| : : : : |\n",
            "| | : | : |\n",
            "|Y| : |B: |\n",
            "+---------+\n",
            "  (Dropoff)\n",
            "\n",
            "Timestep: 63\n",
            "State: 0\n",
            "Action: 5\n",
            "Reward: 20\n",
            "Episode: 4\n",
            "Results after 5 episodes:\n",
            "Average timesteps per episode: 12.6\n",
            "Average penalties per episode: 0.0\n"
          ]
        }
      ],
      "source": [
        "\"\"\"Evaluate agent's performance after Q-learning\"\"\"\n",
        "\n",
        "total_epochs, total_penalties = 0, 0\n",
        "episodes = 5\n",
        "framed = []\n",
        "\n",
        "for e in range(episodes):\n",
        "    state = env.reset()[0]\n",
        "    epochs, penalties, reward = 0, 0, 0\n",
        "\n",
        "    done = False\n",
        "\n",
        "    while not done:\n",
        "        action = np.argmax(q_table[state])\n",
        "        state, reward, done, info, _ = env.step(action)\n",
        "\n",
        "        if reward == -10:\n",
        "            penalties += 1\n",
        "\n",
        "        # Put each rendered frame into dict for animation\n",
        "        framed.append({\n",
        "            'frame': env.render(),\n",
        "            'state': state,\n",
        "            'action': action,\n",
        "            'reward': reward,\n",
        "            \"episode\":e\n",
        "        })\n",
        "        print_frames(framed)\n",
        "        epochs += 1\n",
        "\n",
        "    total_penalties += penalties\n",
        "    total_epochs += epochs\n",
        "\n",
        "print(f\"Results after {episodes} episodes:\")\n",
        "print(f\"Average timesteps per episode: {total_epochs / episodes}\")\n",
        "print(f\"Average penalties per episode: {total_penalties / episodes}\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "f9d22a43-d39e-48f7-b5f9-0972f6407987",
      "metadata": {
        "id": "f9d22a43-d39e-48f7-b5f9-0972f6407987"
      },
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "gymansium",
      "language": "python",
      "name": "gymansium"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.11.6"
    },
    "colab": {
      "provenance": []
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}